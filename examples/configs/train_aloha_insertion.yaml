defaults:
  - env_vars: env_vars
  - _self_

# --- General Configuration ---
seed: 42
window_size: 16              # T_obs: Observation history length
goal_window_size: 16         # T_goal: Future observation chunk size
eval_window_size: 16
batch_size: 64
epochs: 10
eval_freq: 3
eval_on_env_freq: 1
num_env_evals: 5
num_final_evals: 5
num_final_eval_per_goal: 5
action_window_size: 16        # T_act: Action chunk length (usually 1 for policy)
sequentially_select: false

goal_dim: 0                  # 0 for non-goal-conditioned or single-task (will use 'future' obs goal)
visual_input: true           # ⬅️ SET TO TRUE FOR VISUAL TRAINING
vqvae_load_dir: vq_bet_runs/checkpoints/vqbet_aloha_insertion/2025-11-26/02-19-19/major-voice-169/trained_vqvae.pt

wandb:
  project: "vq-bet-aloha-insertion-visual" # Updated project name
  entity: ${env_vars.wandb_entity}

device: cuda
optim:
  lr: 5.5e-5
  weight_decay: 2e-4
  betas: [0.9, 0.999]

# --- Environment Configuration ---
env:
  gym:
    _target_: aloha_insertion_env.ALOHAWRAPPER 
    id: AlohaInsertion-eval-v0
    visual_input: ${visual_input}
    goal_dim: ${goal_dim}

  obs_dim: 512         # D_obs: Low-dimensional state size (e.g., qpos+qvel)
  act_dim: 14         # D_act: Raw action size
  goal_dim: ${goal_dim}

# --- Data Configuration ---
data:
  _target_: dataset.get_lerobot_train_val

  repo_id: ${env_vars.datasets.aloha_insertion_dataset}
  
  goal_conditional: future
  window_size: ${window_size}
  future_seq_len: ${goal_window_size}
  min_future_sep: ${action_window_size}
  action_window_size: ${action_window_size}
  visual_input: ${visual_input}
  vqbet_get_future_action_chunk: true

  transform_list:
    - _target_: torchvision.transforms.ToTensor
    - _target_: torchvision.transforms.Resize
      size: [224, 224]
    - _target_: torchvision.transforms.RandomCrop
      size: [224, 224]
    - _target_: torchvision.transforms.Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]


# --- Checkpoint/Saving ---
save_every: 10
save_path: "${env_vars.save_path}/checkpoints/${env.gym.id}/${now:%Y-%m-%d}/${now:%H-%M-%S}"
load_path: null

# --- Model Configuration ---
model:
  _target_: vq_behavior_transformer.BehaviorTransformer
  obs_dim: ${env.obs_dim}
  act_dim: ${env.act_dim}
  goal_dim: ${env.goal_dim}
  obs_window_size: ${window_size}
  act_window_size: ${action_window_size}
  sequentially_select: ${sequentially_select}
  visual_input: ${visual_input} # ⬅️ SET TO TRUE
  finetune_resnet: false
  
  gpt_model:
    _target_: vq_behavior_transformer.GPT
    config:
      _target_: vq_behavior_transformer.GPTConfig
      # block_size should be T_obs + T_act (10 + 1)
      block_size: 26
      input_dim: ${env.obs_dim}
      n_layer: 6
      n_head: 6
      n_embd: 120

  vqvae_model:
    _target_: vqvae.VqVae
    input_dim_h: ${action_window_size}
    input_dim_w: ${env.act_dim}
    n_latent_dims: 512
    vqvae_n_embed: 16
    vqvae_groups: 2
    eval: true
    device: ${device}
    load_dir: ${vqvae_load_dir}
  offset_loss_multiplier: 100

# --- Goal Function Configuration ---
goal_fn:
  _target_: aloha_insertion_env.get_goal_fn
  data_directory: ${env_vars.datasets.aloha_insertion_dataset}
  
  goal_conditional: ${data.goal_conditional}
  seed: ${seed}
  train_fraction: 0.95
  goal_seq_len: ${goal_window_size}
  unconditional: false
  goal_dim: ${goal_dim}
  visual_input: ${visual_input}
